#53
# review_rater_app.py
# ------------------------------------------------------------
# 오픈소스 LLM(DeepSeek-R1, Ollama 로컬) + Gradio로
# 음식 리뷰 평점을 생성하는 데모 앱.
#
# 기존 코드(Closed LLM + LangChain + OpenAI Key)를
# 오픈소스(로컬) 환경으로 치환:
#  - Gradio 그래픽 UI
#  - Ollama REST API 호출 (requests)
#  - 체인 오브 소트(<think>...</think>) 자동 제거
#  - 점수 범위(rating1~rating2) 유효성 검사 및 추출
# ------------------------------------------------------------

import re
import json
import requests
import gradio as gr

# Ollama 서버 설정(기본: 로컬)
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "deepseek-r1"   # 미설치 시: `ollama pull deepseek-r1`

def strip_think(text: str) -> str:
    """
    DeepSeek 계열이 출력할 수 있는 <think>...</think> 블록 제거
    (보기 좋은 최종 답변만 남김)
    """
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

def build_prompt(review: str, rating1: int, rating2: int) -> str:
    """
    원문의 프롬프트 의도를 유지하되, 모델이 숫자와 설명을 함께 주도록 가이드.
    """
    return (
        "다음 음식 리뷰에 대해 주어진 범위 안에서 점수를 매기고 간단한 근거를 제시해 주세요.\n"
        f"- 리뷰: \"{review}\"\n"
        f"- 점수 범위: {rating1}점 ~ {rating2}점\n\n"
        "출력 형식 예시:\n"
        "점수: 4\n"
        "근거: 배달 포장 아쉬움이 있으나 맛은 좋았음.\n"
    )

def call_ollama(prompt: str, host: str = OLLAMA_HOST, model: str = MODEL_NAME, temperature: float = 0.7) -> str:
    """
    Ollama generate API 호출(스트리밍 미사용, 단일 응답).
    """
    url = f"{host}/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "temperature": temperature,
        "stream": False
    }
    resp = requests.post(url, json=payload, timeout=60)
    if resp.status_code != 200:
        raise RuntimeError(f"Ollama 호출 실패(status={resp.status_code}): {resp.text[:300]}")
    data = resp.json()
    return data.get("response", "")

def extract_rating(text: str, lo: int, hi: int):
    """
    모델 응답에서 첫 번째 정수를 찾아 범위 [lo, hi] 안이면 채택.
    '점수: 4' 같은 형식도 허용.
    """
    # '점수: 4' 혹은 '4점' 등 다양한 형태 커버
    candidates = re.findall(r"[-+]?\d+", text)
    for c in candidates:
        try:
            v = int(c)
            if lo <= v <= hi:
                return v
        except ValueError:
            continue
    return None

def rate_review(review: str, rating1: int, rating2: int, temperature: float):
    """
    Gradio 콜백: 리뷰와 점수 범위를 받아 모델 호출 → 결과 정리.
    """
    # 입력 검증
    if not review.strip():
        return "리뷰를 입력해 주세요.", "", ""
    if rating1 > rating2:
        rating1, rating2 = rating2, rating1  # 순서 보정

    # 프롬프트 구성
    prompt = build_prompt(review, rating1, rating2)

    # 모델 호출
    try:
        raw = call_ollama(prompt, model=MODEL_NAME, temperature=temperature)
    except Exception as e:
        return f"[오류] 모델 호출 실패: {e}", "", ""

    # 체인오브소트 제거
    cleaned = strip_think(raw)

    # 점수 추출
    rating = extract_rating(cleaned, rating1, rating2)

    # 간단한 요약(근거 라인을 찾아서 보여주기)
    reason = ""
    # '근거:'로 시작하는 라인을 우선
    m = re.search(r"(근거\s*:\s*)(.*)", cleaned)
    if m:
        reason = m.group(2).strip()
    else:
        # 첫 줄 이외에서 한두 문장 정도를 근거로 사용
        lines = [ln.strip() for ln in cleaned.splitlines() if ln.strip()]
        if len(lines) >= 2:
            reason = lines[1][:200]

    final_rating = f"{rating} (범위 {rating1}~{rating2})" if rating is not None else "추출 실패(응답 본문 확인)"

    return cleaned, final_rating, reason

# ---------------------------
# Gradio UI
# ---------------------------
EX_REVIEW = "맛은 있었지만 배달 포장이 부족해서 아쉬웠습니다."

with gr.Blocks(title="OpenCode - 리뷰 평점(DeepSeek-R1 / Ollama)") as demo:
    gr.Markdown("## ⭐ 리뷰 평점기 (로컬 LLM)\n로컬 **Ollama + DeepSeek-R1**로 동작합니다. API Key가 필요 없습니다.")

    with gr.Row():
        review = gr.Textbox(label="리뷰 입력", value=EX_REVIEW, lines=3, placeholder="리뷰 문장을 입력하세요.")
    with gr.Row():
        rating1 = gr.Slider(1, 10, step=1, value=1, label="최소 점수")
        rating2 = gr.Slider(1, 10, step=1, value=5, label="최대 점수")
        temperature = gr.Slider(0.0, 1.5, step=0.1, value=0.7, label="창의성(temperature)")

    btn = gr.Button("평가 요청")

    with gr.Row():
        llm_output = gr.Textbox(label="모델 원문 응답", lines=8)
    with gr.Row():
        extracted_rating = gr.Textbox(label="추출된 최종 점수", lines=1)
        reason = gr.Textbox(label="간단 근거", lines=2)

    btn.click(
        fn=rate_review,
        inputs=[review, rating1, rating2, temperature],
        outputs=[llm_output, extracted_rating, reason]
    )

if __name__ == "__main__":
    # 첫 실행 전 모델 설치 필요:
    #   $ ollama pull deepseek-r1
    demo.launch()




