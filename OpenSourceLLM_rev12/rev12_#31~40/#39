#39
import gradio as gr
import subprocess
import json

# Ollamaë¥¼ í†µí•´ ë¡œì»¬ì— ì„¤ì¹˜ëœ DeepSeek-R1 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆì˜í•˜ëŠ” í•¨ìˆ˜
def query_deepseek(user_text):
    """
    Ollama CLIë¥¼ ì‚¬ìš©í•˜ì—¬ DeepSeek-R1 ëª¨ë¸ì— ì§ˆì˜ë¥¼ ë³´ë‚´ê³ ,
    ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # subprocessë¡œ ollama CLI í˜¸ì¶œ
        result = subprocess.run(
            ["ollama", "run", "deepseek-r1", user_text],
            capture_output=True,
            text=True
        )
        return result.stdout.strip()
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {str(e)}"


# Gradio ì¸í„°í˜ì´ìŠ¤ìš© í•¨ìˆ˜
def chat_with_model(user_text):
    """
    Gradio ì…ë ¥(user_text)ì„ ë°›ì•„ LLM ì‘ë‹µì„ ë°˜í™˜
    """
    response = query_deepseek(user_text)
    return response


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ’¬ DeepSeek-R1 ì±—ë´‡ (Ollama ê¸°ë°˜)")
    gr.Markdown("Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ êµ¬í•˜ëŠ” ì½”ë“œ ê°™ì€ ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”!")

    with gr.Row():
        user_input = gr.Textbox(
            label="ì§ˆë¬¸ ì…ë ¥",
            placeholder="ì˜ˆ: Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ ì½”ë“œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
    with gr.Row():
        output = gr.Textbox(
            label="ëª¨ë¸ ì‘ë‹µ",
            placeholder="ì—¬ê¸°ì— DeepSeek-R1 ëª¨ë¸ì˜ ë‹µë³€ì´ í‘œì‹œë©ë‹ˆë‹¤."
        )

    # ë²„íŠ¼ ì´ë²¤íŠ¸
    submit_btn = gr.Button("ì „ì†¡")
    submit_btn.click(fn=chat_with_model, inputs=user_input, outputs=output)

# ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()




