#50 (조코딩 시작)
# ======================================================
# OpenCode 변환본: OpenAI → Ollama(DeepSeek-R1)
# ------------------------------------------------------
# 실행 준비:
#   1) Ollama 설치 (https://ollama.com/download)
#   2) 모델 다운로드:  `ollama pull deepseek-r1:latest`
#   3) 기본 서버는 localhost:11434 에서 실행됨
# ======================================================

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Ollama용 Chat 모델
try:
    from langchain_ollama import ChatOllama  # 최신 버전
except ImportError:
    from langchain_community.chat_models import ChatOllama  # 구버전 fallback

# LLM 초기화 (DeepSeek-R1, 로컬 실행)
llm = ChatOllama(
    model="deepseek-r1:latest",   # Ollama에서 설치한 모델명
    temperature=0.7,              # 창의성 정도
)

# 프롬프트 템플릿 정의
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("user", "{input}")
])

# 출력 파서
output_parser = StrOutputParser()

# 체인 구성 (프롬프트 → LLM → 파서)
chain = prompt | llm | output_parser

# 실행
result = chain.invoke({"input": "hi"})
print(result)


