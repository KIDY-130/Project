#55
# lodging_review_chain_ollama.py
# ------------------------------------------------------------
# ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ LLM (Ollama + DeepSeek-R1) + Gradio UI
# ê¸°ì¡´ LangChain(OpenAI) íŒŒì´í”„ë¼ì¸ì„ ë¡œì»¬ë¡œ ì¹˜í™˜:
#   1) ë¦¬ë·°ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
#   2) ë²ˆì—­ë¬¸ í•œ ë¬¸ì¥ ìš”ì•½
#   3) ë²ˆì—­ë¬¸ ê¸°ë°˜ ê°ì„± ì ìˆ˜(0~10, ìˆ«ìë§Œ)
#   4) ì›ë¬¸ ë¦¬ë·°ì˜ ì–¸ì–´ ê°ì§€(ì–¸ì–´ëª…ë§Œ)
#   5) ìš”ì•½ì— ëŒ€í•´ 'í•´ë‹¹ ì–¸ì–´'ë¡œ ê³µì†í•œ ë‹µë³€ ì‘ì„±
#   6) ê·¸ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­
# ------------------------------------------------------------

import re
import json
import requests
from typing import Optional, Tuple, Dict
import gradio as gr

# -----------------------------
# í™˜ê²½ ì„¤ì • (ë¡œì»¬ Ollama)
# -----------------------------
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "deepseek-r1"   # í•„ìš”ì‹œ ë‹¤ë¥¸ ë¡œì»¬ ëª¨ë¸ëª…ìœ¼ë¡œ êµì²´ ê°€ëŠ¥ (ì˜ˆ: "qwen2.5:14b")

# -----------------------------
# ê³µìš© ìœ í‹¸
# -----------------------------
def strip_think(text: str) -> str:
    """
    DeepSeek ê³„ì—´ ëª¨ë¸ì´ ì¶œë ¥í•˜ëŠ” <think>...</think> ë¸”ë¡ ì œê±°
    (ì‚¬ìš©ìì—ê² ìµœì¢… ë‹µë³€ë§Œ ë³´ì´ë„ë¡ ì •ë¦¬)
    """
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

def ollama_generate(prompt: str, model: str = MODEL_NAME, temperature: float = 0.7, host: str = OLLAMA_HOST) -> str:
    """
    Ollama /api/generate (non-stream) í˜¸ì¶œ
    """
    resp = requests.post(
        f"{host}/api/generate",
        json={"model": model, "prompt": prompt, "temperature": temperature, "stream": False},
        timeout=60,
    )
    if resp.status_code != 200:
        raise RuntimeError(f"Ollama í˜¸ì¶œ ì‹¤íŒ¨(status={resp.status_code}): {resp.text[:300]}")
    data = resp.json()
    return data.get("response", "")

# -----------------------------
# 1) ë¦¬ë·° â†’ í•œêµ­ì–´ ë²ˆì—­
# -----------------------------
def translate_to_korean(review: str, temperature: float) -> str:
    prompt = (
        "ë‹¤ìŒ ìˆ™ë°• ì‹œì„¤ ë¦¬ë·°ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\n"
        "ê°€ëŠ¥í•˜ë©´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³  ì˜ë¯¸ ë³´ì¡´ì— ì‹ ê²½ ì¨ ì£¼ì„¸ìš”.\n\n"
        f"[ì›ë¬¸ ë¦¬ë·°]\n{review}\n\n"
        "[ì¶œë ¥: í•œêµ­ì–´ ë²ˆì—­ë§Œ]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 2) ë²ˆì—­ë¬¸ ìš”ì•½ (í•œ ë¬¸ì¥)
# -----------------------------
def summarize_translation(translation: str, temperature: float) -> str:
    prompt = (
        "ë‹¤ìŒ í•œêµ­ì–´ ë¦¬ë·° ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.\n"
        "ë¬¸ì¥ ìˆ˜ëŠ” ì •í™•íˆ 1ë¬¸ì¥ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”.\n\n"
        f"[ë¦¬ë·° ë²ˆì—­]\n{translation}\n\n"
        "[ì¶œë ¥: í•œ ë¬¸ì¥ ìš”ì•½]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 3) ê°ì„± ì ìˆ˜ (0~10, ìˆ«ìë§Œ)
# -----------------------------
def sentiment_score_from_translation(translation: str, temperature: float) -> str:
    prompt = (
        "ë‹¤ìŒ í•œêµ­ì–´ ë¦¬ë·° ë²ˆì—­ì„ ì½ê³  ì „ë°˜ì  ë§Œì¡±ë„ë¥¼ 0~10 ì‚¬ì´ 'ì •ìˆ˜ í•œ ê°œ'ë¡œ í‰ê°€í•˜ì„¸ìš”.\n"
        "- 0ì€ ë§¤ìš° ë¶€ì •ì , 10ì€ ë§¤ìš° ê¸ì •ì ì…ë‹ˆë‹¤.\n"
        "- ë°˜ë“œì‹œ ìˆ«ìë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: 7\n\n"
        f"[ë¦¬ë·° ë²ˆì—­]\n{translation}\n\n"
        "[ì¶œë ¥: ìˆ«ìë§Œ]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    cleaned = strip_think(raw)
    m = re.search(r"\b([0-9]|10)\b", cleaned)
    return m.group(1) if m else "5"  # ì•ˆì „ ê¸°ë³¸ê°’

# -----------------------------
# 4) ì›ë¬¸ ì–¸ì–´ ê°ì§€ (ì–¸ì–´ëª…ë§Œ)
# -----------------------------
def detect_language(review: str, temperature: float) -> str:
    prompt = (
        "ë‹¤ìŒ ìˆ™ë°• ì‹œì„¤ ë¦¬ë·°ì— ì‚¬ìš©ëœ ì–¸ì–´ê°€ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.\n"
        "ì–¸ì–´ ì´ë¦„ë§Œ í•œ ë‹¨ì–´(ë˜ëŠ” ë‘ ë‹¨ì–´)ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: English, Korean, Spanish\n\n"
        f"[ì›ë¬¸ ë¦¬ë·°]\n{review}\n\n"
        "[ì¶œë ¥: ì–¸ì–´ëª…ë§Œ]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw).splitlines()[0].strip()

# -----------------------------
# 5) ê³µì†í•œ ë‹µë³€(ì›ë¬¸ ì–¸ì–´)
# -----------------------------
def polite_reply_in_language(summary_ko: str, language: str, temperature: float) -> str:
    prompt = (
        "You are a hotel representative.\n"
        "Write a polite, concise reply (2-4 sentences) to the following Korean summary of a guest review.\n"
        f"Use this language for the reply: {language}\n"
        "- Express thanks, acknowledge pros/cons, and show willingness to improve without over-apologizing.\n\n"
        f"[Korean Summary]\n{summary_ko}\n\n"
        "[Reply in the requested language only]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 6) ë‹µë³€ â†’ í•œêµ­ì–´ ë²ˆì—­
# -----------------------------
def reply_to_korean(reply_foreign: str, temperature: float) -> str:
    prompt = (
        "ë‹¤ìŒ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê³  ì •ì¤‘í•œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\n\n"
        f"[ì›ë¬¸ ë‹µë³€]\n{reply_foreign}\n\n"
        "[ì¶œë ¥: í•œêµ­ì–´ ë²ˆì—­]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# -----------------------------
def run_pipeline(review: str, temperature: float = 0.7, model: str = MODEL_NAME):
    global MODEL_NAME
    MODEL_NAME = model or MODEL_NAME

    review = (review or "").strip()
    if not review:
        return "ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", "", "", "", "", ""

    try:
        translation = translate_to_korean(review, temperature)
    except Exception as e:
        return f"[ë²ˆì—­ ì˜¤ë¥˜] {e}", "", "", "", "", ""

    try:
        summary = summarize_translation(translation, temperature)
    except Exception as e:
        return translation, f"[ìš”ì•½ ì˜¤ë¥˜] {e}", "", "", "", ""

    try:
        score = sentiment_score_from_translation(translation, temperature)
    except Exception as e:
        return translation, summary, f"[ê°ì„± ì ìˆ˜ ì˜¤ë¥˜] {e}", "", "", ""

    try:
        language = detect_language(review, temperature)
    except Exception as e:
        return translation, summary, score, f"[ì–¸ì–´ ê°ì§€ ì˜¤ë¥˜] {e}", "", ""

    try:
        reply1 = polite_reply_in_language(summary, language, temperature)
    except Exception as e:
        return translation, summary, score, language, f"[ë‹µë³€ ìƒì„± ì˜¤ë¥˜] {e}", ""

    try:
        reply2 = reply_to_korean(reply1, temperature)
    except Exception as e:
        return translation, summary, score, language, reply1, f"[í•œêµ­ì–´ ë²ˆì—­ ì˜¤ë¥˜] {e}"

    return translation, summary, score, language, reply1, reply2

# -----------------------------
# Gradio UI
# -----------------------------
EX_REVIEW = """The hotel was clean and the staff were very helpful.
The location was convenient, close to many attractions.
However, the room was a bit small and the breakfast options were limited.
Overall, a decent stay but there is room for improvement.
"""

with gr.Blocks(title="OpenCode - ìˆ™ë°• ë¦¬ë·° íŒŒì´í”„ë¼ì¸ (Ollama + DeepSeek-R1)") as demo:
    gr.Markdown("## ğŸ¨ ìˆ™ë°• ë¦¬ë·° íŒŒì´í”„ë¼ì¸\në¡œì»¬ **Ollama + DeepSeek-R1**ë¡œ ë™ì‘í•©ë‹ˆë‹¤. API Keyê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.")

    with gr.Row():
        tb_review = gr.Textbox(label="ì›ë³¸ ìˆ™ë°• ë¦¬ë·° ì…ë ¥", value=EX_REVIEW, lines=8, placeholder="ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ ë„£ìœ¼ì„¸ìš”.")
    with gr.Row():
        tb_model = gr.Textbox(label="ëª¨ë¸ ì´ë¦„", value=MODEL_NAME, placeholder="ì˜ˆ: deepseek-r1, qwen2.5:14b, llama3.1:8b ë“±")
        sl_temp = gr.Slider(0.0, 1.5, value=0.7, step=0.1, label="Temperature(ì°½ì˜ì„±)")

    btn = gr.Button("ì‹¤í–‰")

    with gr.Row():
        out_translation = gr.Textbox(label="â‘  í•œêµ­ì–´ ë²ˆì—­", lines=6)
    with gr.Row():
        out_summary = gr.Textbox(label="â‘¡ ìš”ì•½(í•œ ë¬¸ì¥)", lines=2)
        out_score = gr.Textbox(label="â‘¢ ê°ì„± ì ìˆ˜(0~10, ìˆ«ì)", lines=1)
    with gr.Row():
        out_language = gr.Textbox(label="â‘£ ì›ë¬¸ ì–¸ì–´ ê°ì§€", lines=1)
    with gr.Row():
        out_reply1 = gr.Textbox(label="â‘¤ ê³µì†í•œ ë‹µë³€(ì›ë¬¸ ì–¸ì–´)", lines=6)
    with gr.Row():
        out_reply2 = gr.Textbox(label="â‘¥ ê³µì†í•œ ë‹µë³€(í•œêµ­ì–´ ë²ˆì—­)", lines=6)

    btn.click(
        fn=run_pipeline,
        inputs=[tb_review, sl_temp, tb_model],
        outputs=[out_translation, out_summary, out_score, out_language, out_reply1, out_reply2]
    )

if __name__ == "__main__":
    # ìµœì´ˆ 1íšŒ:  ollama pull deepseek-r1
    demo.launch()




