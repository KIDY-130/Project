#55
# lodging_review_chain_ollama.py
# ------------------------------------------------------------
# 로컬 오픈소스 LLM (Ollama + DeepSeek-R1) + Gradio UI
# 기존 LangChain(OpenAI) 파이프라인을 로컬로 치환:
#   1) 리뷰를 한국어로 번역
#   2) 번역문 한 문장 요약
#   3) 번역문 기반 감성 점수(0~10, 숫자만)
#   4) 원문 리뷰의 언어 감지(언어명만)
#   5) 요약에 대해 '해당 언어'로 공손한 답변 작성
#   6) 그 답변을 한국어로 번역
# ------------------------------------------------------------

import re
import json
import requests
from typing import Optional, Tuple, Dict
import gradio as gr

# -----------------------------
# 환경 설정 (로컬 Ollama)
# -----------------------------
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "deepseek-r1"   # 필요시 다른 로컬 모델명으로 교체 가능 (예: "qwen2.5:14b")

# -----------------------------
# 공용 유틸
# -----------------------------
def strip_think(text: str) -> str:
    """
    DeepSeek 계열 모델이 출력하는 <think>...</think> 블록 제거
    (사용자에겐 최종 답변만 보이도록 정리)
    """
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

def ollama_generate(prompt: str, model: str = MODEL_NAME, temperature: float = 0.7, host: str = OLLAMA_HOST) -> str:
    """
    Ollama /api/generate (non-stream) 호출
    """
    resp = requests.post(
        f"{host}/api/generate",
        json={"model": model, "prompt": prompt, "temperature": temperature, "stream": False},
        timeout=60,
    )
    if resp.status_code != 200:
        raise RuntimeError(f"Ollama 호출 실패(status={resp.status_code}): {resp.text[:300]}")
    data = resp.json()
    return data.get("response", "")

# -----------------------------
# 1) 리뷰 → 한국어 번역
# -----------------------------
def translate_to_korean(review: str, temperature: float) -> str:
    prompt = (
        "다음 숙박 시설 리뷰를 자연스럽고 정확하게 한국어로 번역하세요.\n"
        "가능하면 존댓말을 사용하고 의미 보존에 신경 써 주세요.\n\n"
        f"[원문 리뷰]\n{review}\n\n"
        "[출력: 한국어 번역만]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 2) 번역문 요약 (한 문장)
# -----------------------------
def summarize_translation(translation: str, temperature: float) -> str:
    prompt = (
        "다음 한국어 리뷰 내용을 한 문장으로 간결하게 요약하세요.\n"
        "문장 수는 정확히 1문장으로 제한하세요.\n\n"
        f"[리뷰 번역]\n{translation}\n\n"
        "[출력: 한 문장 요약]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 3) 감성 점수 (0~10, 숫자만)
# -----------------------------
def sentiment_score_from_translation(translation: str, temperature: float) -> str:
    prompt = (
        "다음 한국어 리뷰 번역을 읽고 전반적 만족도를 0~10 사이 '정수 한 개'로 평가하세요.\n"
        "- 0은 매우 부정적, 10은 매우 긍정적입니다.\n"
        "- 반드시 숫자만 출력하세요. 예: 7\n\n"
        f"[리뷰 번역]\n{translation}\n\n"
        "[출력: 숫자만]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    cleaned = strip_think(raw)
    m = re.search(r"\b([0-9]|10)\b", cleaned)
    return m.group(1) if m else "5"  # 안전 기본값

# -----------------------------
# 4) 원문 언어 감지 (언어명만)
# -----------------------------
def detect_language(review: str, temperature: float) -> str:
    prompt = (
        "다음 숙박 시설 리뷰에 사용된 언어가 무엇인지 판단하세요.\n"
        "언어 이름만 한 단어(또는 두 단어)로 출력하세요. 예: English, Korean, Spanish\n\n"
        f"[원문 리뷰]\n{review}\n\n"
        "[출력: 언어명만]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw).splitlines()[0].strip()

# -----------------------------
# 5) 공손한 답변(원문 언어)
# -----------------------------
def polite_reply_in_language(summary_ko: str, language: str, temperature: float) -> str:
    prompt = (
        "You are a hotel representative.\n"
        "Write a polite, concise reply (2-4 sentences) to the following Korean summary of a guest review.\n"
        f"Use this language for the reply: {language}\n"
        "- Express thanks, acknowledge pros/cons, and show willingness to improve without over-apologizing.\n\n"
        f"[Korean Summary]\n{summary_ko}\n\n"
        "[Reply in the requested language only]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 6) 답변 → 한국어 번역
# -----------------------------
def reply_to_korean(reply_foreign: str, temperature: float) -> str:
    prompt = (
        "다음 답변을 자연스럽고 정중한 한국어로 번역하세요.\n\n"
        f"[원문 답변]\n{reply_foreign}\n\n"
        "[출력: 한국어 번역]\n"
    )
    raw = ollama_generate(prompt, temperature=temperature)
    return strip_think(raw)

# -----------------------------
# 전체 실행 파이프라인
# -----------------------------
def run_pipeline(review: str, temperature: float = 0.7, model: str = MODEL_NAME):
    global MODEL_NAME
    MODEL_NAME = model or MODEL_NAME

    review = (review or "").strip()
    if not review:
        return "리뷰를 입력하세요.", "", "", "", "", ""

    try:
        translation = translate_to_korean(review, temperature)
    except Exception as e:
        return f"[번역 오류] {e}", "", "", "", "", ""

    try:
        summary = summarize_translation(translation, temperature)
    except Exception as e:
        return translation, f"[요약 오류] {e}", "", "", "", ""

    try:
        score = sentiment_score_from_translation(translation, temperature)
    except Exception as e:
        return translation, summary, f"[감성 점수 오류] {e}", "", "", ""

    try:
        language = detect_language(review, temperature)
    except Exception as e:
        return translation, summary, score, f"[언어 감지 오류] {e}", "", ""

    try:
        reply1 = polite_reply_in_language(summary, language, temperature)
    except Exception as e:
        return translation, summary, score, language, f"[답변 생성 오류] {e}", ""

    try:
        reply2 = reply_to_korean(reply1, temperature)
    except Exception as e:
        return translation, summary, score, language, reply1, f"[한국어 번역 오류] {e}"

    return translation, summary, score, language, reply1, reply2

# -----------------------------
# Gradio UI
# -----------------------------
EX_REVIEW = """The hotel was clean and the staff were very helpful.
The location was convenient, close to many attractions.
However, the room was a bit small and the breakfast options were limited.
Overall, a decent stay but there is room for improvement.
"""

with gr.Blocks(title="OpenCode - 숙박 리뷰 파이프라인 (Ollama + DeepSeek-R1)") as demo:
    gr.Markdown("## 🏨 숙박 리뷰 파이프라인\n로컬 **Ollama + DeepSeek-R1**로 동작합니다. API Key가 필요 없습니다.")

    with gr.Row():
        tb_review = gr.Textbox(label="원본 숙박 리뷰 입력", value=EX_REVIEW, lines=8, placeholder="리뷰 텍스트를 붙여 넣으세요.")
    with gr.Row():
        tb_model = gr.Textbox(label="모델 이름", value=MODEL_NAME, placeholder="예: deepseek-r1, qwen2.5:14b, llama3.1:8b 등")
        sl_temp = gr.Slider(0.0, 1.5, value=0.7, step=0.1, label="Temperature(창의성)")

    btn = gr.Button("실행")

    with gr.Row():
        out_translation = gr.Textbox(label="① 한국어 번역", lines=6)
    with gr.Row():
        out_summary = gr.Textbox(label="② 요약(한 문장)", lines=2)
        out_score = gr.Textbox(label="③ 감성 점수(0~10, 숫자)", lines=1)
    with gr.Row():
        out_language = gr.Textbox(label="④ 원문 언어 감지", lines=1)
    with gr.Row():
        out_reply1 = gr.Textbox(label="⑤ 공손한 답변(원문 언어)", lines=6)
    with gr.Row():
        out_reply2 = gr.Textbox(label="⑥ 공손한 답변(한국어 번역)", lines=6)

    btn.click(
        fn=run_pipeline,
        inputs=[tb_review, sl_temp, tb_model],
        outputs=[out_translation, out_summary, out_score, out_language, out_reply1, out_reply2]
    )

if __name__ == "__main__":
    # 최초 1회:  ollama pull deepseek-r1
    demo.launch()




