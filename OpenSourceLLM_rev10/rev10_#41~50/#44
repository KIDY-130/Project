#44
"""
LlamaIndex + Ollama (DeepSeek-R1) RAG ë°ëª¨ + Reranker(ì¬ë­í‚¹) ì¶”ê°€
- ë¡œì»¬ LLM/ì„ë² ë”©(Ollama) + SentenceTransformerRerankë¡œ ê´€ë ¨ ë¬¸ì„œ ì¬ìˆœìœ„í™”
- Gradio UIì—ì„œ Reranker ì˜¨/ì˜¤í”„, ëª¨ë¸ëª…, top_k/top_n ì„¤ì • ê°€ëŠ¥

ì‚¬ì „ ì¤€ë¹„
1) Ollama ì„¤ì¹˜/ì‹¤í–‰ ë° ëª¨ë¸ ì¤€ë¹„:
   - ì–¸ì–´ëª¨ë¸:  ollama pull deepseek-r1
   - ì„ë² ë”©:    ollama pull nomic-embed-text
2) íŒ¨í‚¤ì§€ ì„¤ì¹˜:
   pip install "llama-index>=0.10.0" llama-index-llms-ollama llama-index-embeddings-ollama \
               gradio requests pypdf beautifulsoup4 sentence-transformers
"""

from __future__ import annotations
import os
from pathlib import Path
from typing import Dict, Optional, List

import gradio as gr

# LlamaIndex í•µì‹¬
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
    Settings,
)

# Ollama LLM/ì„ë² ë”©
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding

# ì›¹ ë¡œë”
from llama_index.readers.web import BeautifulSoupWebReader

# ---- Reranker (ì—¬ëŸ¬ ë²„ì „ í˜¸í™˜ ì„í¬íŠ¸) ----
# LlamaIndex ë²„ì „ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
SentenceTransformerRerank = None
try:
    # ì‹ ë²„ì „
    from llama_index.postprocessor.sentence_transformer_rerank import SentenceTransformerRerank  # type: ignore
except Exception:
    try:
        # êµ¬ë²„ì „
        from llama_index.postprocessor.sbert_rerank import SentenceTransformerRerank  # type: ignore
    except Exception:
        SentenceTransformerRerank = None


# ---------------------------
# ì „ì—­ ì„¤ì •: ë¡œì»¬ LLM + ì„ë² ë”©
# ---------------------------
DEFAULT_LLM_MODEL = "deepseek-r1"
DEFAULT_EMBED_MODEL = "nomic-embed-text"

def configure_llamaindex(
    llm_model: str = DEFAULT_LLM_MODEL,
    embed_model: str = DEFAULT_EMBED_MODEL,
    temperature: float = 0.2,
    top_p: float = 0.95,
):
    """
    LlamaIndex ì „ì—­ Settingsì— ë¡œì»¬ Ollama LLM/ì„ë² ë”© ì„¤ì •
    """
    Settings.llm = Ollama(
        model=llm_model,
        request_timeout=120,
        temperature=temperature,
        top_p=top_p,
    )
    Settings.embed_model = OllamaEmbedding(model_name=embed_model)


# ---------------------------
# ê³µí†µ ìœ í‹¸: ìƒ‰ì¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------
def build_index_from_documents(documents, persist_dir: str) -> VectorStoreIndex:
    index = VectorStoreIndex.from_documents(documents)
    index.storage_context.persist(persist_dir=persist_dir)
    return index

def load_index(persist_dir: str) -> VectorStoreIndex:
    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
    return load_index_from_storage(storage_context)


# ---------------------------
# ë°ì´í„° ì†ŒìŠ¤ë³„ ìƒ‰ì¸ ìƒì„±
# ---------------------------
def index_local_folder(folder_path: str, persist_dir: str) -> str:
    folder = Path(folder_path)
    if not folder.exists() or not folder.is_dir():
        return f"[ì˜¤ë¥˜] í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}"

    documents = SimpleDirectoryReader(folder_path).load_data()
    index = build_index_from_documents(documents, persist_dir)
    _ = index.as_query_engine()
    return f"[ì™„ë£Œ] í´ë” ìƒ‰ì¸ ìƒì„± ë° ì €ì¥: {persist_dir} (ë¬¸ì„œ ìˆ˜: {len(documents)})"

def index_web_urls(urls_text: str, persist_dir: str) -> str:
    urls: List[str] = []
    for token in urls_text.replace(",", "\n").splitlines():
        u = token.strip()
        if u:
            urls.append(u)
    if not urls:
        return "[ì˜¤ë¥˜] ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤."

    loader = BeautifulSoupWebReader()
    documents = loader.load_data(urls=urls)
    index = build_index_from_documents(documents, persist_dir)
    _ = index.as_query_engine()
    return f"[ì™„ë£Œ] ì›¹ ë¬¸ì„œ ìƒ‰ì¸ ìƒì„± ë° ì €ì¥: {persist_dir} (ë¬¸ì„œ ìˆ˜: {len(documents)})"

def index_pdf_files(file_paths_text: str, persist_dir: str) -> str:
    paths: List[Path] = []
    for token in file_paths_text.replace(",", "\n").splitlines():
        p = Path(token.strip())
        if p.exists() and p.is_file() and p.suffix.lower() == ".pdf":
            paths.append(p)
    if not paths:
        return "[ì˜¤ë¥˜] ìœ íš¨í•œ PDF íŒŒì¼ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤."

    documents = SimpleDirectoryReader(input_files=paths).load_data()
    index = build_index_from_documents(documents, persist_dir)
    _ = index.as_query_engine()
    return f"[ì™„ë£Œ] PDF ìƒ‰ì¸ ìƒì„± ë° ì €ì¥: {persist_dir} (ë¬¸ì„œ ìˆ˜: {len(documents)})"


# ---------------------------
# Rerankerë¥¼ í¬í•¨í•œ Query Engine êµ¬ì„±
# ---------------------------
def make_query_engine_with_rerank(
    index: VectorStoreIndex,
    similarity_top_k: int = 8,
    use_reranker: bool = True,
    rerank_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
    rerank_top_n: int = 4,
    response_mode: str = "default",
):
    """
    - similarity_top_k: 1ì°¨ ë²¡í„° ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
    - use_reranker: ì¬ë­í‚¹ ì‚¬ìš© ì—¬ë¶€
    - rerank_model: Sentence-Transformers êµì°¨ì¸ì½”ë” ëª¨ë¸ëª…
    - rerank_top_n: ì¬ë­í‚¹ í›„ ìµœì¢… ìƒìœ„ ë¬¸ì„œ ìˆ˜(<= similarity_top_k)
    - response_mode: LlamaIndex ì‘ë‹µ í•©ì„± ëª¨ë“œ
    """
    retriever = index.as_retriever(similarity_top_k=similarity_top_k)

    node_postprocessors = []
    if use_reranker:
        if SentenceTransformerRerank is None:
            raise RuntimeError(
                "SentenceTransformerRerank ì„í¬íŠ¸ ì‹¤íŒ¨. 'sentence-transformers' ë° LlamaIndex ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš”.\n"
                "pip install sentence-transformers"
            )
        reranker = SentenceTransformerRerank(
            top_n=rerank_top_n,
            model=rerank_model,
        )
        node_postprocessors.append(reranker)

    qe = index.as_query_engine(
        retriever=retriever,
        node_postprocessors=node_postprocessors,
        response_mode=response_mode,
    )
    return qe


# ---------------------------
# ì§ˆì˜ í•¨ìˆ˜ (UIì—ì„œ í˜¸ì¶œ)
# ---------------------------
def query_index(
    persist_dir: str,
    user_query: str,
    response_mode: str,
    similarity_top_k: int,
    use_reranker: bool,
    rerank_model: str,
    rerank_top_n: int,
) -> str:
    if not user_query.strip():
        return "[ì˜¤ë¥˜] ì§ˆì˜ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”."

    try:
        index = load_index(persist_dir)
    except Exception as e:
        return f"[ì˜¤ë¥˜] ìƒ‰ì¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒ‰ì¸ì„ ìƒì„±í•˜ì„¸ìš”.\n- persist_dir: {persist_dir}\n- ìƒì„¸: {e}"

    try:
        qe = make_query_engine_with_rerank(
            index=index,
            similarity_top_k=int(similarity_top_k),
            use_reranker=bool(use_reranker),
            rerank_model=rerank_model.strip(),
            rerank_top_n=int(rerank_top_n),
            response_mode=response_mode,
        )
    except Exception as e:
        return f"[ì˜¤ë¥˜] Query Engine ìƒì„± ì‹¤íŒ¨: {e}"

    res = qe.query(user_query)
    return str(res)


# ---------------------------
# Gradio UI
# ---------------------------
with gr.Blocks(title="LlamaIndex + Ollama (DeepSeek-R1) RAG ë°ëª¨ + Reranker") as demo:
    gr.Markdown("## ğŸ” LlamaIndex + Ollama (DeepSeek-R1) + Reranker")
    gr.Markdown(
        "- ë¡œì»¬ **Ollama LLM/ì„ë² ë”©** ê¸°ë°˜ RAG\n"
        "- **SentenceTransformerRerank**ë¡œ ì¬ìˆœìœ„í™”(êµì°¨ ì¸ì½”ë”)\n"
        "- ì‘ì€ ëª¨ë¸ë¶€í„° ì‹œì‘í•´ ì„±ëŠ¥/ì†ë„ë¥¼ ê· í˜• ìˆê²Œ ì¡°ì ˆí•˜ì„¸ìš”"
    )

    # ì „ì—­ ëª¨ë¸ ì„¤ì •
    with gr.Accordion("âš™ï¸ ì „ì—­ LLM/ì„ë² ë”© ì„¤ì • (Ollama)", open=True):
        with gr.Row():
            llm_model = gr.Textbox(label="LLM ëª¨ë¸", value=DEFAULT_LLM_MODEL, scale=2)
            embed_model = gr.Textbox(label="ì„ë² ë”© ëª¨ë¸", value=DEFAULT_EMBED_MODEL, scale=2)
        with gr.Row():
            temperature = gr.Slider(0.0, 1.5, value=0.2, step=0.05, label="temperature", scale=1)
            top_p = gr.Slider(0.1, 1.0, value=0.95, step=0.05, label="top_p", scale=1)
        apply_btn = gr.Button("ëª¨ë¸ ì„¤ì • ì ìš©", variant="primary")

    # ìƒ‰ì¸ ìƒì„± íƒ­
    with gr.Tabs():
        with gr.Tab("ğŸ“ í´ë” ìƒ‰ì¸"):
            with gr.Row():
                folder_path = gr.Textbox(label="í´ë” ê²½ë¡œ", value="data", scale=3)
                persist_dir_folder = gr.Textbox(label="ì €ì¥ ê²½ë¡œ(persist_dir)", value="storage_folder", scale=2)
            build_folder_btn = gr.Button("í´ë” ìƒ‰ì¸ ìƒì„±/ì €ì¥", variant="primary")
            folder_status = gr.Textbox(label="ìƒíƒœ", lines=3)

        with gr.Tab("ğŸŒ ì›¹ URL ìƒ‰ì¸"):
            urls_text = gr.Textbox(
                label="URL ëª©ë¡ (ì‰¼í‘œ/ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
                placeholder="ì˜ˆ) https://www.law.go.kr/ë²•ë ¹/ëŒ€í•œë¯¼êµ­í—Œë²•",
                lines=3,
            )
            persist_dir_web = gr.Textbox(label="ì €ì¥ ê²½ë¡œ(persist_dir)", value="storage_web")
            build_web_btn = gr.Button("ì›¹ ìƒ‰ì¸ ìƒì„±/ì €ì¥", variant="primary")
            web_status = gr.Textbox(label="ìƒíƒœ", lines=3)

        with gr.Tab("ğŸ“„ PDF ìƒ‰ì¸"):
            pdf_paths_text = gr.Textbox(
                label="PDF ê²½ë¡œ ëª©ë¡ (ì‰¼í‘œ/ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
                placeholder="ì˜ˆ) ./attention.pdf",
                lines=3,
            )
            persist_dir_pdf = gr.Textbox(label="ì €ì¥ ê²½ë¡œ(persist_dir)", value="storage_pdf")
            build_pdf_btn = gr.Button("PDF ìƒ‰ì¸ ìƒì„±/ì €ì¥", variant="primary")
            pdf_status = gr.Textbox(label="ìƒíƒœ", lines=3)

    # ì§ˆì˜ ì˜ì—­ + Reranker ì„¤ì •
    gr.Markdown("---")
    gr.Markdown("### ğŸ’¬ ì§ˆì˜í•˜ê¸° (ì €ì¥ëœ ìƒ‰ì¸ ëŒ€ìƒ) + ğŸ” Reranker ì„¤ì •")
    with gr.Row():
        persist_dir_query = gr.Textbox(label="ëŒ€ìƒ persist_dir", value="storage_folder", scale=2)
        response_mode = gr.Dropdown(
            ["default", "compact", "tree_summarize", "accumulate"],
            value="default",
            label="response_mode",
            scale=1,
        )
    with gr.Row():
        similarity_top_k = gr.Slider(1, 50, value=8, step=1, label="similarity_top_k (1ì°¨ ê²€ìƒ‰ ê°œìˆ˜)")
        use_reranker = gr.Checkbox(label="Reranker ì‚¬ìš©", value=True)
    with gr.Row():
        rerank_model = gr.Textbox(
            label="Reranker ëª¨ë¸ (Sentence-Transformers)",
            value="cross-encoder/ms-marco-MiniLM-L-6-v2",
            placeholder="ì˜ˆ) cross-encoder/ms-marco-MiniLM-L-6-v2, BAAI/bge-reranker-base",
        )
        rerank_top_n = gr.Slider(1, 50, value=4, step=1, label="rerank_top_n (ì¬ë­í‚¹ í›„ ìµœì¢… ê°œìˆ˜)")

    user_query = gr.Textbox(
        label="ì§ˆì˜",
        placeholder="ì˜ˆ) What did the author do growing up? / í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜",
        lines=2,
    )
    ask_btn = gr.Button("ì§ˆì˜ ì‹¤í–‰ ğŸš€", variant="primary")
    answer_box = gr.Textbox(label="ì‘ë‹µ", lines=12)

    # ì´ë²¤íŠ¸ ë°”ì¸ë”©
    def _apply_models(llm, emb, temp, tp):
        configure_llamaindex(llm, emb, temp, tp)
        return f"[ì ìš©ë¨] LLM={llm}, EMB={emb}, temperature={temp}, top_p={tp}"

    apply_btn.click(
        fn=_apply_models,
        inputs=[llm_model, embed_model, temperature, top_p],
        outputs=[folder_status],
    )
    build_folder_btn.click(fn=index_local_folder, inputs=[folder_path, persist_dir_folder], outputs=[folder_status])
    build_web_btn.click(fn=index_web_urls, inputs=[urls_text, persist_dir_web], outputs=[web_status])
    build_pdf_btn.click(fn=index_pdf_files, inputs=[pdf_paths_text, persist_dir_pdf], outputs=[pdf_status])

    ask_btn.click(
        fn=query_index,
        inputs=[
            persist_dir_query,
            user_query,
            response_mode,
            similarity_top_k,
            use_reranker,
            rerank_model,
            rerank_top_n,
        ],
        outputs=[answer_box],
    )

# ìµœì´ˆ 1íšŒ ì „ì—­ ëª¨ë¸ ì„¤ì •
configure_llamaindex()

if __name__ == "__main__":
    demo.launch()




