#70
"""
OpenCode ë³€í™˜ ê·œì¹™ ì ìš© ë²„ì „
- Closed LLM(OpenAI) â†’ ì˜¤í”ˆì†ŒìŠ¤ LLM(Ollama + DeepSeek-R1)
- API Key ì‚¬ìš© ì œê±°
- Gradio ê·¸ë˜í”½ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ë¡œì»¬ PCì— LLM/ì„ë² ë”© ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ëŠ” ì „ì œ

ì‚¬ì „ ì¤€ë¹„(í„°ë¯¸ë„ì—ì„œ 1íšŒ ì‹¤í–‰):
    ollama pull deepseek-r1:latest
    ollama pull mxbai-embed-large   # ë˜ëŠ” nomic-embed-text ë“±

í•„ìš” íŒ¨í‚¤ì§€(ì˜ˆì‹œ):
    pip install -U langchain langchain-community langchain-ollama faiss-cpu gradio wikipedia arxiv

ì£¼ì˜:
- LangChain ë²„ì „ì— ë”°ë¼ ì¼ë¶€ APIê°€ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ë³¸ ì½”ë“œëŠ” 2025 ì‹œì  ê¸°ì¤€ ì¼ë°˜ì ì¸ êµ¬ì„±ì„ ì‚¬ìš©).
- create_openai_tools_agent â†’ ReAct ê¸°ë°˜ ì¼ë°˜ ì—ì´ì „íŠ¸ë¡œ ëŒ€ì²´(DeepSeek-R1ì€ OpenAIì‹ í•¨ìˆ˜í˜¸ì¶œ ë¯¸ì§€ì›).
"""

from typing import Tuple
import gradio as gr

# LangChain í•µì‹¬/ì»¤ë®¤ë‹ˆí‹°/OLLAMA í†µí•©
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper
from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool

# ì—ì´ì „íŠ¸ êµ¬ì„± ìš”ì†Œ
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool

# ================================
# 1) ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ LLM/ì„ë² ë”© ì„¤ì •
# ================================
# DeepSeek-R1(ì¶”ë¡ í˜•) ëª¨ë¸ì„ Ollamaì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
llm = ChatOllama(
    model="deepseek-r1:latest",   # ë¡œì»¬ì— pullëœ ëª¨ë¸ íƒœê·¸
    temperature=0.1,               # ì¼ê´€ì„± í™•ë³´ë¥¼ ìœ„í•œ ë‚®ì€ ì˜¨ë„ê°’
    num_ctx=8192,                  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(í™˜ê²½ì— ë§ê²Œ ì¡°ì •)
)

# ë¡œì»¬ ì„ë² ë”© ëª¨ë¸(OllamaEmbeddings). ê³ ì •ë°€ ì„ë² ë”© ëª¨ë¸ ê¶Œì¥.
embeddings = OllamaEmbeddings(model="mxbai-embed-large")

# ================================
# 2) ì™¸ë¶€ ë„êµ¬(Wikipedia/Arxiv) ë˜í¼
# ================================
# Wikipedia API ì„¤ì • : top_k_results = ê²°ê³¼ ìˆ˜, doc_content_chars_max = ë¬¸ì„œ ê¸¸ì´ ì œí•œ
wiki_api = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)
wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)

# arXiv API ì„¤ì •
arxiv_api = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200, load_all_available_meta=False)
arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api)

# ================================
# 3) ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ í¬ë¡¤ë§ â†’ ë²¡í„°DB êµ¬ì¶•(FAISS)
# ================================
#   - WebBaseLoaderëŠ” ë‹¨ì¼ URL í¬ë¡¤ë§ ì˜ˆì‹œì…ë‹ˆë‹¤.
#   - ì‹¤ì œ ë‰´ìŠ¤ ìš”ì•½/ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ë ¤ë©´ ê¸°ì‚¬ ê°œë³„ URL ìˆ˜ì§‘ + ë‹¤ì¤‘ ë¡œë”©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
loader = WebBaseLoader("https://news.naver.com/")
docs = loader.load()  # ì›¹ ë¬¸ì„œ ë¡œë“œ

# ë¬¸ì„œ ë¶„í• : 1000ì chunk, 200ì ì¤‘ì²©
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
documents = splitter.split_documents(docs)

# FAISS ë²¡í„°DB ìƒì„±(ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ì‚¬ìš©)
vectordb = FAISS.from_documents(documents, embeddings)
retriever = vectordb.as_retriever()

# LangChain retrieverë¥¼ Toolë¡œ ë˜í•‘
retriever_tool = create_retriever_tool(
    retriever,
    name="naver_news_search",
    description="ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ë¡œì»¬ ë²¡í„°DB. ë‹¹ì¼ ê¸°ì‚¬/ì£¼ìš” ì´ìŠˆë¥¼ ì°¾ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©."
)

# ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬ ëª¨ìŒ
TOOLS = [wiki_tool, arxiv_tool, retriever_tool]

# ================================
# 4) ReAct ì—ì´ì „íŠ¸ìš© í”„ë¡¬í”„íŠ¸
# ================================
# OpenAI í•¨ìˆ˜í˜¸ì¶œ ì „ìš© í”„ë¡¬í”„íŠ¸ ëŒ€ì‹ , ì¼ë°˜ ReAct ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì •ì˜í•©ë‹ˆë‹¤.
react_prompt = ChatPromptTemplate.from_messages([
    ("system",
     """
     ë„ˆëŠ” í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” ìœ ëŠ¥í•œ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ì•¼.
     ë„ˆì—ê²ŒëŠ” ë‹¤ìŒ ë„êµ¬ë“¤ì´ ìˆë‹¤: Wikipedia, arXiv, naver_news_search(ë¡œì»¬ ë²¡í„°DB).
     ì§ˆì˜ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•´ ë‹¨ê³„ì ìœ¼ë¡œ ìƒê°í•˜ê³ (í•„ìš”ì‹œ), ì¶œì²˜/ê·¼ê±°ë¥¼ ìš”ì•½í•´ì¤˜.
     ë¶ˆí™•ì‹¤í•˜ë©´ ì •ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³ , ê³¼ë„í•œ ì¶”ì¸¡ì€ í”¼í•˜ë¼.
     ìµœì¢… ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•˜ë¼.
     """
    ),
    # ì—ì´ì „íŠ¸ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì¶”ë¡ /ë„êµ¬ í˜¸ì¶œì„ í•˜ë‹¤ê°€ ë§ˆì§€ë§‰ì— ìµœì¢… ë‹µë§Œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê²Œ ë¨.
    ("human", "{input}"),
    MessagesPlaceholder("agent_scratchpad"),  # ReAct ì²´ì¸ìš© scratchpad
])

# ReAct ì—ì´ì „íŠ¸ êµ¬ì„±
agent = create_react_agent(llm=llm, tools=TOOLS, prompt=react_prompt)

# AgentExecutor: ì—ì´ì „íŠ¸ì™€ íˆ´ì„ ì‹¤í–‰í•˜ëŠ” ì»¨í…Œì´ë„ˆ
agent_executor = AgentExecutor(agent=agent, tools=TOOLS, verbose=True)

# ================================
# 5) ë‹¨ì¼ í˜¸ì¶œ í•¨ìˆ˜(Gradioì—ì„œ ì‚¬ìš©)
# ================================
DEFAULT_QUESTION = "ì˜¤ëŠ˜ ë¶€ë™ì‚° ê´€ë ¨ ì£¼ìš” ì†Œì‹ì„ ì•Œë ¤ì¤˜"

def run_agent(user_input: str) -> Tuple[str, str]:
    """ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ìµœì¢… ë‹µë³€ê³¼ ì‚¬ìš©ëœ ë„êµ¬ íŒíŠ¸ë¥¼ ë°˜í™˜.
    - ë°˜í™˜ê°’[0]: ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸
    - ë°˜í™˜ê°’[1]: (ì„ íƒ) ë¶€ê°€ ì •ë³´/ë””ë²„ê·¸ í…ìŠ¤íŠ¸
    """
    if not user_input or not user_input.strip():
        user_input = DEFAULT_QUESTION

    # AgentExecutor.invokeëŠ” dict ì…ë ¥/ì¶œë ¥ì„ ì‚¬ìš©
    result = agent_executor.invoke({"input": user_input})

    # result ì˜ˆì‹œ: {"input": "...", "output": "ìµœì¢…ë‹µë³€"}
    final_answer = result.get("output", "")

    # ê°„ë‹¨í•œ ë””ë²„ê·¸/ë„êµ¬ ì‚¬ìš© íŒíŠ¸(verbosenessê°€ ì½˜ì†”ì— ë‚˜ì˜¤ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìµœì†Œí™”)
    debug_note = "ë„êµ¬: Wikipedia / arXiv / naver_news_search ì¤‘ í•„ìš”ì‹œ ìë™ ì‚¬ìš©"
    return final_answer, debug_note

# ================================
# 6) Gradio UI
# ================================
with gr.Blocks(title="OpenCode: LangChain + Ollama Agent") as demo:
    gr.Markdown("""
    # ğŸ” ì˜¤í”ˆì†ŒìŠ¤ LLM ê¸°ë°˜ ë‰´ìŠ¤/ì§€ì‹ ì—ì´ì „íŠ¸
    - **ì—”ì§„**: Ollama + DeepSeek-R1 (ë¡œì»¬)
    - **ì„ë² ë”©**: mxbai-embed-large (ë¡œì»¬)
    - **ë„êµ¬**: Wikipedia / arXiv / ë¡œì»¬ FAISS(ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤ëƒ…ìƒ·)

    ì•„ë˜ ì…ë ¥ì°½ì— í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”. (ì˜ˆ: *ì˜¤ëŠ˜ ë¶€ë™ì‚° ê´€ë ¨ ì£¼ìš” ì†Œì‹ì„ ì•Œë ¤ì¤˜*)
    """)

    with gr.Row():
        inp = gr.Textbox(label="ì§ˆë¬¸", value=DEFAULT_QUESTION, lines=2)
    with gr.Row():
        btn = gr.Button("ğŸš€ ì‹¤í–‰", variant="primary")
    with gr.Row():
        out_answer = gr.Markdown(label="ì—ì´ì „íŠ¸ ì‘ë‹µ")
    with gr.Accordion("ì„¸ë¶€ ì •ë³´(ê°„ë‹¨)", open=False):
        out_debug = gr.Markdown()

    def _on_click(q):
        answer, dbg = run_agent(q)
        return answer, dbg

    btn.click(_on_click, inputs=[inp], outputs=[out_answer, out_debug])

# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
if __name__ == "__main__":
    # local URL ì¶œë ¥, ê³µìœ  ê³µê°œ X
    demo.launch()


# ollama pull deepseek-r1:latest
# ollama pull mxbai-embed-large
# !pip install -U langchain langchain-community langchain-ollama faiss-cpu gradio # wikipedia arxiv

